{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Conceptos básicos de Pytorch\n",
    "En este tutorial veremos algunos conceptos importantes para poder comenzar a utilizar pytorch para tareas de deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "Un **tensor** es un arreglo multidimensional con elementos del mismo tipo (dtype). En escencia, un tensor de pytorch es muy similar en comportamiento a un array de numpy con algunas diferencias y funcionalidades agregadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas\n",
    "Veremos como crear y definir tensores usando pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# crear un tensor de rango 0, un escalar, no contiene ejes\n",
    "simple_tensor = torch.tensor(4)\n",
    "print(simple_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "# un tensor de rango 1 es similar a una lista de valores, tiene un eje\n",
    "r1_tensor = torch.tensor([2.0,3.0,4.0,5.0])\n",
    "print(r1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4., 5.],\n",
      "        [1., 2., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# un tensor de rango 2 es una matriz\n",
    "r2_tensor = torch.tensor([[2.0,3.0,4.0,5.0],[1.0,2.0,0.0,1.0]])\n",
    "print(r2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# un tensor puede tener un numero arbitrario de ejes o dimensiones\n",
    "rank_3_tensor = torch.tensor([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],], dtype=torch.float32)\n",
    "                    \n",
    "print(rank_3_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas de visualizar un tensor de más de 2 dimensiones\n",
    "![tensor](3atensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3. 4. 5.]\n",
      " [1. 2. 0. 1.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# se puede convertir un tensor a un array de numpy de varias maneras:\n",
    "M = np.array(r2_tensor)\n",
    "M2 = r2_tensor.numpy()\n",
    "print(M)\n",
    "print(type(M2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [4, 5]]) \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[3, 3],\n",
      "        [7, 7]]) \n",
      "\n",
      "numpy: [[3 3]\n",
      " [7 7]]\n",
      "tensor([[2, 3],\n",
      "        [4, 5]]) \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[3, 3],\n",
      "        [7, 7]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# se pueden realizar operaciones basicas con tensores como adicion, multiplicacion y multiplicacion de matrices\n",
    "a = torch.tensor([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = torch.tensor([[1, 1],\n",
    "                 [1, 1]]) # tambien se puede usar `tf.ones([2,2])`\n",
    "\n",
    "print(torch.add(a, b), \"\\n\")\n",
    "print(torch.multiply(a, b), \"\\n\")\n",
    "print(torch.matmul(a, b), \"\\n\")\n",
    "print('numpy:',np.dot(a.numpy(), b.numpy()))\n",
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor(2)\n",
      "tensor([[2.6894e-01, 7.3106e-01],\n",
      "        [9.9988e-01, 1.2339e-04]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/cy_ykqys6wl_gc741r9fs8mr0000gn/T/ipykernel_18061/1877532574.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(c))\n"
     ]
    }
   ],
   "source": [
    "# se pueden usar tensores en todo tipo de operaciones adicionales\n",
    "c = torch.tensor([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# valor maximo\n",
    "print(torch.max(c))\n",
    "# indice del valor maximo\n",
    "print(torch.argmax(c))\n",
    "# calcular la funcion softmax\n",
    "print(torch.nn.functional.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen alguas definiciones importantes (similares a numpy):\n",
    "\n",
    "  - **shape** es el tamaño (numero de elementos) de cada dimension de un tensor.\n",
    "  - **rank** es el numero de dimensiones del tensor, un escalar tiene rank 0, una matriz rank 2\n",
    "  - **axis** o **dimension** es una dimensión en particular de un tensor.\n",
    "  - **size** el numero total de elementos de un tensor, el producto del vector *shape*.\n",
    "  \n",
    "Podemos visualizar para un tensor de rank 4\n",
    "\n",
    "\n",
    "![r4](4atensor.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de cada elemento: torch.float32\n",
      "Numero de dimensiones: 4\n",
      "Shape: torch.Size([3, 2, 4, 5])\n",
      "Elementos en el eje 0 del tensor: 3\n",
      "Elementos en el ultimo eje del tensor: 5\n",
      "Numero total de elementos (3*2*4*5):  120\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor = torch.zeros([3, 2, 4, 5])\n",
    "\n",
    "print(\"Tipo de cada elemento:\", rank_4_tensor.dtype)\n",
    "print(\"Numero de dimensiones:\", rank_4_tensor.ndim)\n",
    "print(\"Shape:\", rank_4_tensor.shape)\n",
    "print(\"Elementos en el eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elementos en el ultimo eje del tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Numero total de elementos (3*2*4*5): \", rank_4_tensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  2  3  5  8 13 21 34]\n",
      "First: 0\n",
      "Second: 1\n",
      "Last: 34\n",
      "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
      "Before 4: [0 1 1 2]\n",
      "From 4 to the end: [ 3  5  8 13 21 34]\n",
      "From 2, before 7: [1 2 3 5 8]\n",
      "Every other item: [ 0  1  3  8 21]\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor = torch.tensor([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "# indexado con un escalar\n",
    "print(rank_1_tensor.numpy())\n",
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())\n",
    "# indexado con un slice\n",
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "4.0\n",
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_2_tensor = torch.tensor([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=torch.float16)\n",
    "print(rank_2_tensor.numpy())\n",
    "                            \n",
    "# pasando un entero por cada dimension, arroja un escalar\n",
    "print(rank_2_tensor[1, 1].numpy())\n",
    "\n",
    "# Se puede indexar usando combinaciones de escalares y slices\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12., 13., 14.],\n",
      "         [15., 16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23., 24.],\n",
      "         [25., 26., 27., 28., 29.]]])\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# ejemplo de un tensor de 3 dimensiones\n",
    "print(rank_3_tensor[:, :, 4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3slice](3rslice.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# los tensores son mutables\n",
    "mi_variable = torch.tensor([1, 2, 3])\n",
    "print(mi_variable + 1)\n",
    "v = torch.tensor(0.0)\n",
    "w = v + 1 \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo automático de gradientes\n",
    "\n",
    "Para poder usar la capacidad de diferenciación automática de pytorch, se necesita recordar todas las operaciones que han ocurrido y el orden de ocurrencia durante el *forward pass*. Luego, durante el *backward pass*, pytorch puede recorrer la lista de operaciones y calcular las gradientes.\n",
    "\n",
    "### autograd\n",
    "Pytorch provee la API de **torch.autograd** para la diferenciación automática y poder calcular las gradientes de un grafo de cómputo con respecto a ciertas variables de entrada. Pytorch \"recuerda\" todas las operaciones ejecutadas dentro un contexto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x107483790>\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "# y = x ^ 2\n",
    "y = x ** 2\n",
    "# dy = 2x\n",
    "y.backward()\n",
    "dy_dx = x.grad\n",
    "print(y.grad_fn)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(7.0, requires_grad=True)\n",
    "y = x + 4\n",
    "z = y ** 2 - 6\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9., 9.], grad_fn=<MulBackward0>)\n",
      "tensor([6., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.0, 3.0], requires_grad=True)\n",
    "\n",
    "z = torch.multiply(x, x)\n",
    "\n",
    "print(z)\n",
    "\n",
    "z.backward(torch.tensor([1, 1]))\n",
    "# Find derivative of z with respect to the original input tensor x\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede solicitar gradientes de la salida con respecto a valores intermedios calculados durante una \"grabación\" de un contexto tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0, 3.0], requires_grad=True)\n",
    "y = torch.multiply(x, x)\n",
    "z = torch.multiply(y, y)\n",
    "z.backward(torch.tensor([1, 1]))\n",
    "# dz_dx = 2 * y, donde: y = x ^ 2\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion lineal en pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([442, 11]) torch.Size([442])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import random\n",
    "# X y y ya son arrays de numpy\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "m = X.shape[0]\n",
    "unos = np.ones((m, 1))\n",
    "X = np.append(unos, X, axis=1)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62eb3e910e44ea0e9978ea29c6f3fc7540fb99bfa181faf1a80d42ed442aa249"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('unifranz': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
